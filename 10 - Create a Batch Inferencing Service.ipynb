{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create a Batch Inferencing Service\n",
    "\n",
    "Imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the diabetes prediction model can be used to process all of the day's patient data as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with patients who are predicted to be at risk of diabetes. With Azure Machine Learning, you can accomplish this by creating a *batch inferencing pipeline*; and that's what you'll implement in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.33.0 to work with dp-100-module1-ml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and register a model\n",
    "\n",
    "Now let's train and register a model to deploy in a batch inferencing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: mslearn-train-diabetes\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8903333333333333\n",
      "AUC: 0.8775983879795015\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and upload batch data\n",
    "\n",
    "Since we don't actually have a fully staffed clinic with patients from whom to get new data for this exercise, you'll generate a random sample from our diabetes CSV file, upload that data to a datastore in the Azure Machine Learning workspace, and register a dataset for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceartifactstore - Default = False\n",
      "azureml_globaldatasets - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n",
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n",
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/10.csv\n",
      "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/100.csv\n",
      "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/11.csv\n",
      "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/12.csv\n",
      "Uploaded batch-data/12.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/13.csv\n",
      "Uploaded batch-data/13.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/14.csv\n",
      "Uploaded batch-data/14.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/15.csv\n",
      "Uploaded batch-data/15.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data/16.csv\n",
      "Uploaded batch-data/16.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/17.csv\n",
      "Uploaded batch-data/17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/18.csv\n",
      "Uploaded batch-data/18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/19.csv\n",
      "Uploaded batch-data/19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/2.csv\n",
      "Uploaded batch-data/2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/20.csv\n",
      "Uploaded batch-data/20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/21.csv\n",
      "Uploaded batch-data/21.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/22.csv\n",
      "Uploaded batch-data/22.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data/23.csv\n",
      "Uploaded batch-data/23.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/24.csv\n",
      "Uploaded batch-data/24.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/25.csv\n",
      "Uploaded batch-data/25.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/26.csv\n",
      "Uploaded batch-data/26.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/27.csv\n",
      "Uploaded batch-data/27.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/28.csv\n",
      "Uploaded batch-data/28.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/29.csv\n",
      "Uploaded batch-data/29.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/3.csv\n",
      "Uploaded batch-data/3.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/30.csv\n",
      "Uploaded batch-data/30.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/31.csv\n",
      "Uploaded batch-data/31.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/32.csv\n",
      "Uploaded batch-data/32.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/33.csv\n",
      "Uploaded batch-data/33.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data/34.csv\n",
      "Uploaded batch-data/34.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/35.csv\n",
      "Uploaded batch-data/35.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/36.csv\n",
      "Uploaded batch-data/36.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/38.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/39.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/37.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/4.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/40.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/41.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/42.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/43.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploaded batch-data/44.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/45.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/46.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/47.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/48.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/49.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/5.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploaded batch-data/51.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/52.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/53.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/54.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/55.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/56.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/57.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/58.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/59.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/6.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/60.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/61.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/62.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/63.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/64.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/66.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/67.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/75.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/76.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploaded batch-data/77.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/78.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/79.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/8.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/80.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/81.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/84.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/85.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/86.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploaded batch-data/87.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/88.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/89.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/9.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/91.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/92.csv, 91 files out of an estimated total of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch-data/83.csv\n",
      "Uploaded batch-data/83.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/90.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploaded batch-data/98.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/99.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set default data store\n",
    "ws.set_default_datastore('workspaceblobstore')\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
    "\n",
    "# Load the diabetes data\n",
    "diabetes = pd.read_csv('data/diabetes2.csv')\n",
    "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
    "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute\n",
    "\n",
    "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"dp100clusterday2\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        inference_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
    "\n",
    "## Create a pipeline for batch inferencing\n",
    "\n",
    "Now we're ready to define the pipeline we'll use for batch inferencing. Our pipeline will need Python code to perform the batch inferencing, so let's create a folder where we can keep all the files used by the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_diabetes.py\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read the comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will need an environment in which to run, so we'll create a Conda specification that includes the packages that the code uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_environment.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define a run context that includes the Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a **ParallelRunStep**, which enables the batch data to be processed in parallel and the results collated in a single output file named *parallel_run_step.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"batch_diabetes.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-diabetes',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put the step into a pipeline, and run it.\n",
    "\n",
    "> **Note**: This may take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-diabetes [1709d5ed][20d7c65b-f8c3-4358-a10a-4ca367d7e076], (This step is eligible to reuse a previous run's output)\n",
      "Submitted PipelineRun f710fcc9-20f6-4da5-98c4-4292f3d93ce2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f710fcc9-20f6-4da5-98c4-4292f3d93ce2?wsid=/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourcegroups/dp100-esi-course/workspaces/dp-100-module1-ml&tid=a9c3340e-e390-4e58-8d69-193d480ee19a\n",
      "PipelineRunId: f710fcc9-20f6-4da5-98c4-4292f3d93ce2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f710fcc9-20f6-4da5-98c4-4292f3d93ce2?wsid=/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourcegroups/dp100-esi-course/workspaces/dp-100-module1-ml&tid=a9c3340e-e390-4e58-8d69-193d480ee19a\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 95976bd4-cfa1-462d-a90a-e0b580ccb54f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/95976bd4-cfa1-462d-a90a-e0b580ccb54f?wsid=/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourcegroups/dp100-esi-course/workspaces/dp-100-module1-ml&tid=a9c3340e-e390-4e58-8d69-193d480ee19a\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/09/15 16:19:55 Downloading source code...\n",
      "2021/09/15 16:19:57 Finished downloading source code\n",
      "2021/09/15 16:19:57 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/09/15 16:19:57 Successfully set up Docker network: acb_default_network\n",
      "2021/09/15 16:19:57 Setting up Docker configuration...\n",
      "2021/09/15 16:19:58 Successfully set up Docker configuration\n",
      "2021/09/15 16:19:58 Logging in to registry: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io\n",
      "2021/09/15 16:19:59 Successfully logged into 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io\n",
      "2021/09/15 16:19:59 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/09/15 16:19:59 Scanning for dependencies...\n",
      "2021/09/15 16:19:59 Successfully scanned dependencies\n",
      "2021/09/15 16:19:59 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/19 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1@sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1@sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "25fa05cd42bd: Pulling fs layer\n",
      "d919a1754444: Pulling fs layer\n",
      "503f8e7b8f00: Pulling fs layer\n",
      "bdabc678f352: Pulling fs layer\n",
      "032131447e0e: Pulling fs layer\n",
      "2563f27cea79: Pulling fs layer\n",
      "5d58346cd085: Pulling fs layer\n",
      "9833a4023137: Pulling fs layer\n",
      "d709a6919501: Pulling fs layer\n",
      "bdabc678f352: Waiting\n",
      "032131447e0e: Waiting\n",
      "2563f27cea79: Waiting\n",
      "5d58346cd085: Waiting\n",
      "9833a4023137: Waiting\n",
      "d709a6919501: Waiting\n",
      "503f8e7b8f00: Verifying Checksum\n",
      "503f8e7b8f00: Download complete\n",
      "25fa05cd42bd: Verifying Checksum\n",
      "25fa05cd42bd: Download complete\n",
      "bdabc678f352: Verifying Checksum\n",
      "bdabc678f352: Download complete\n",
      "2563f27cea79: Verifying Checksum\n",
      "2563f27cea79: Download complete\n",
      "032131447e0e: Verifying Checksum\n",
      "032131447e0e: Download complete\n",
      "5d58346cd085: Verifying Checksum\n",
      "5d58346cd085: Download complete\n",
      "d709a6919501: Verifying Checksum\n",
      "d709a6919501: Download complete\n",
      "9833a4023137: Verifying Checksum\n",
      "9833a4023137: Download complete\n",
      "d919a1754444: Verifying Checksum\n",
      "d919a1754444: Download complete\n",
      "25fa05cd42bd: Pull complete\n",
      "d919a1754444: Pull complete\n",
      "503f8e7b8f00: Pull complete\n",
      "bdabc678f352: Pull complete\n",
      "032131447e0e: Pull complete\n",
      "2563f27cea79: Pull complete\n",
      "5d58346cd085: Pull complete\n",
      "9833a4023137: Pull complete\n",
      "d709a6919501: Pull complete\n",
      "Digest: sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1@sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c\n",
      " ---> f5193fa1f6ad\n",
      "Step 2/19 : USER root\n",
      " ---> Running in 1d29629b3f40\n",
      "Removing intermediate container 1d29629b3f40\n",
      " ---> d5d5a74756aa\n",
      "Step 3/19 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 14b687500101\n",
      "Removing intermediate container 14b687500101\n",
      " ---> 852a3bdb25a7\n",
      "Step 4/19 : WORKDIR /\n",
      " ---> Running in 8a97268135de\n",
      "Removing intermediate container 8a97268135de\n",
      " ---> 438f0764981c\n",
      "Step 5/19 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> f3748e3f8ceb\n",
      "Step 6/19 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in f257debaf6df\n",
      "Removing intermediate container f257debaf6df\n",
      " ---> f2dcf97e4e4e\n",
      "Step 7/19 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 15c963994d72\n",
      "Step 8/19 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 264ecc96e982\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "openssl-1.0.2u       | 2.2 MB    |            |   0% \n",
      "openssl-1.0.2u       | 2.2 MB    | ########## | 100% \n",
      "openssl-1.0.2u       | 2.2 MB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 113 KB    |            |   0% \n",
      "ca-certificates-2021 | 113 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.37.0         | 33 KB     |            |   0% \n",
      "wheel-0.37.0         | 33 KB     | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.5.0 | 22 KB     |            |   0% \n",
      "libgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n",
      "\n",
      "setuptools-52.0.0    | 724 KB    |            |   0% \n",
      "setuptools-52.0.0    | 724 KB    | ########## | 100% \n",
      "\n",
      "libgfortran4-7.5.0   | 995 KB    |            |   0% \n",
      "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
      "\n",
      "numpy-1.19.2         | 22 KB     |            |   0% \n",
      "numpy-1.19.2         | 22 KB     | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "libgomp-9.3.0        | 311 KB    |            |   0% \n",
      "libgomp-9.3.0        | 311 KB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.3.0        | 170 KB    |            |   0% \n",
      "mkl_fft-1.3.0        | 170 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.3.0      | 4.8 MB    |            |   0% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.2    | 4.1 MB    |            |   0% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2021.3. | 1.4 MB    |            |   0% \n",
      "intel-openmp-2021.3. | 1.4 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 151 KB    |            |   0% \n",
      "libedit-3.1          | 151 KB    | ########## | 100% \n",
      "\n",
      "pip-21.2.2           | 1.8 MB    |            |   0% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 14.4 MB   |            |   0% \n",
      "scipy-1.5.2          | 14.4 MB   | ####9      |  49% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "\n",
      "_openmp_mutex-4.5    | 22 KB     |            |   0% \n",
      "_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 808 KB    |            |   0% \n",
      "sqlite-3.23.1        | 808 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.0 MB    |            |   0% \n",
      "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
      "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
      "\n",
      "joblib-1.0.1         | 208 KB    |            |   0% \n",
      "joblib-1.0.1         | 208 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 781 KB    |            |   0% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 103 KB    |            |   0% \n",
      "zlib-1.2.11          | 103 KB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 23.6 MB   |            |   0% \n",
      "python-3.6.2         | 23.6 MB   | ###2       |  32% \n",
      "python-3.6.2         | 23.6 MB   | ########4  |  85% \n",
      "python-3.6.2         | 23.6 MB   | ########## | 100% \n",
      "\n",
      "certifi-2021.5.30    | 139 KB    |            |   0% \n",
      "certifi-2021.5.30    | 139 KB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 48 KB     |            |   0% \n",
      "libffi-3.2.1         | 48 KB     | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
      "\n",
      "six-1.16.0           | 18 KB     |            |   0% \n",
      "six-1.16.0           | 18 KB     | ########## | 100% \n",
      "\n",
      "scikit-learn-0.24.2  | 5.2 MB    |            |   0% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "\n",
      "mkl-2020.2           | 138.3 MB  |            |   0% \n",
      "mkl-2020.2           | 138.3 MB  | 5          |   6% \n",
      "mkl-2020.2           | 138.3 MB  | #2         |  12% \n",
      "mkl-2020.2           | 138.3 MB  | ##         |  21% \n",
      "mkl-2020.2           | 138.3 MB  | ##8        |  28% \n",
      "mkl-2020.2           | 138.3 MB  | ###6       |  37% \n",
      "mkl-2020.2           | 138.3 MB  | ####4      |  44% \n",
      "mkl-2020.2           | 138.3 MB  | #####3     |  54% \n",
      "mkl-2020.2           | 138.3 MB  | ######2    |  63% \n",
      "mkl-2020.2           | 138.3 MB  | #######1   |  72% \n",
      "mkl-2020.2           | 138.3 MB  | ########1  |  81% \n",
      "mkl-2020.2           | 138.3 MB  | ########9  |  90% \n",
      "mkl-2020.2           | 138.3 MB  | #########8 |  98% \n",
      "mkl-2020.2           | 138.3 MB  | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.1     | 327 KB    |            |   0% \n",
      "mkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 848 KB    |            |   0% \n",
      "readline-7.0         | 848 KB    | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 52 KB     |            |   0% \n",
      "mkl-service-2.3.0    | 52 KB     | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 341 KB    |            |   0% \n",
      "xz-5.2.5             | 341 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.o8qvqhwc.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.34.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.34.0\n",
      "  Downloading azureml_dataset_runtime-1.34.0-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencensus-ext-azure==1.0.8\n",
      "  Downloading opencensus_ext_azure-1.0.8-py2.py3-none-any.whl (35 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting azureml-core~=1.34.0\n",
      "  Downloading azureml_core-1.34.0-py3-none-any.whl (2.2 MB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting azureml-inference-server-http~=0.3.1\n",
      "  Downloading azureml_inference_server_http-0.3.1-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o8qvqhwc.requirements.txt (line 1)) (52.0.0.post20210125)\n",
      "Collecting requests>=2.19.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "Collecting opencensus<1.0.0,>=0.7.13\n",
      "  Downloading opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n",
      "Collecting urllib3<=1.26.6,>=1.23\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-8.1.0-py2.py3-none-any.whl (796 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting docker<6.0.0\n",
      "  Downloading docker-5.0.2-py2.py3-none-any.whl (145 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-9.1.0-py2.py3-none-any.whl (314 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azure-core<2.0.0,>=1.15.0\n",
      "  Downloading azure_core-1.18.0-py2.py3-none-any.whl (166 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.34.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o8qvqhwc.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting azureml-dataprep<2.23.0a,>=2.22.0a\n",
      "  Downloading azureml_dataprep-2.22.2-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow<4.0.0,>=0.17.0\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Requirement already satisfied: numpy!=1.19.3 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.34.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o8qvqhwc.requirements.txt (line 1)) (1.19.2)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.21-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting azureml-dataprep-rslex~=1.20.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.20.2-cp36-cp36m-manylinux1_x86_64.whl (10.9 MB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.14.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting inference-schema==1.1.0\n",
      "  Downloading inference_schema-1.1.0-py3-none-any.whl (19 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting wrapt==1.11.1\n",
      "  Downloading wrapt-1.11.1.tar.gz (27 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib/python3.6/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.34.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o8qvqhwc.requirements.txt (line 1)) (2021.5.30)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.31.2-py2.py3-none-any.whl (93 kB)\n",
      "Collecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Collecting packaging>=14.3\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting google-auth<2.0dev,>=1.25.0\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.5-py3-none-any.whl (37 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp36-cp36m-manylinux1_x86_64.whl (552 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.16-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (103 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Building wheels for collected packages: json-logging-py, wrapt, fusepy, contextvars\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3925 sha256=efa0982e47cf9d13d45441b4722cd709d84d6b110946032768b996dfa2d78a4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=69887 sha256=81a9a96c149a9388349210f9741bcb3d3ada3ff0a36762290fe88c0c743c10ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/0f/ec/66085641573800014bb0c8b657f3366eff641c42df79abbfe9\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10502 sha256=a3b88ac8019f77a1fc8b4555ee570237cde548b8d21346431574a226807b91d3\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for contextvars (setup.py): started\n",
      "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
      "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=56687c066fb3bac25b9e80a099421f0d11e48d4dcdbad7a896f592e2ecd1ce9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built json-logging-py wrapt fusepy contextvars\n",
      "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, requests, typing-extensions, pyasn1, portalocker, oauthlib, msal, zipp, rsa, requests-oauthlib, python-dateutil, pyparsing, pyasn1-modules, protobuf, msal-extensions, isodate, immutables, distro, cachetools, azure-core, pytz, packaging, msrest, MarkupSafe, importlib-metadata, googleapis-common-protos, google-auth, dotnetcore2, contextvars, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, werkzeug, websocket-client, ruamel.yaml.clib, pyopenssl, pyarrow, opencensus-context, msrestazure, Jinja2, jeepney, itsdangerous, google-api-core, click, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, SecretStorage, ruamel.yaml, psutil, pathspec, opencensus, ndg-httpsclient, jsonpickle, jmespath, inference-schema, gunicorn, fusepy, flask, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, opencensus-ext-azure, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.1 MarkupSafe-2.0.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.18.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.1.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.34.0 azureml-dataprep-2.22.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-1.20.2 azureml-dataset-runtime-1.34.0 azureml-defaults-1.34.0 azureml-inference-server-http-0.3.1 backports.tempfile-1.0 backports.weakref-1.0.post1 cachetools-4.2.2 cffi-1.14.6 charset-normalizer-2.0.5 click-8.0.1 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-3.4.8 distro-1.6.0 docker-5.0.2 dotnetcore2-2.1.21 flask-1.0.3 fusepy-3.0.1 google-api-core-1.31.2 google-auth-1.35.0 googleapis-common-protos-1.53.0 gunicorn-20.1.0 idna-3.2 immutables-0.16 importlib-metadata-4.8.1 inference-schema-1.1.0 isodate-0.6.0 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 msal-1.14.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.1 opencensus-0.7.13 opencensus-context-0.1.2 opencensus-ext-azure-1.0.8 packaging-21.0 pathspec-0.9.0 portalocker-1.7.1 protobuf-3.17.3 psutil-5.8.0 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyopenssl-20.0.1 pyparsing-2.4.7 python-dateutil-2.8.2 pytz-2021.1 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.6 typing-extensions-3.10.0.2 urllib3-1.26.6 websocket-client-1.2.1 werkzeug-1.0.1 wrapt-1.11.1 zipp-3.5.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "\n",
      "Removing intermediate container 264ecc96e982\n",
      " ---> cc7d15a3d548\n",
      "Step 9/19 : ENV PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/bin:$PATH\n",
      " ---> Running in 777675b64618\n",
      "Removing intermediate container 777675b64618\n",
      " ---> de7c67343544\n",
      "Step 10/19 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 680fd19b401b\n",
      "Step 11/19 : RUN echo \"Copying environment context\"\n",
      " ---> Running in d05feaf7e265\n",
      "Copying environment context\n",
      "Removing intermediate container d05feaf7e265\n",
      " ---> 7ac7a22ce3af\n",
      "Step 12/19 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 8c65274429da\n",
      "Step 13/19 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      " ---> Running in c27f7bca8bbe\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container c27f7bca8bbe\n",
      " ---> 4d96d3ebed88\n",
      "Step 14/19 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d\n",
      " ---> Running in ec52ce4435ed\n",
      "Removing intermediate container ec52ce4435ed\n",
      " ---> c941e7c85775\n",
      "Step 15/19 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e220b045f6c3c3008b1a386af067185d/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in d1cb2b9746c0\n",
      "Removing intermediate container d1cb2b9746c0\n",
      " ---> dfc785ab8cc5\n",
      "Step 16/19 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 0eba23a2bcab\n",
      "Step 17/19 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 6a0091fe15ae\n",
      "Removing intermediate container 6a0091fe15ae\n",
      " ---> 69b9d6478993\n",
      "Step 18/19 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in e5d4c4f41b32\n",
      "Removing intermediate container e5d4c4f41b32\n",
      " ---> 62bcf1e23aaa\n",
      "Step 19/19 : CMD [\"bash\"]\n",
      " ---> Running in def903533e52\n",
      "Removing intermediate container def903533e52\n",
      " ---> 757e3ccc56a2\n",
      "Successfully built 757e3ccc56a2\n",
      "Successfully tagged 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:latest\n",
      "Successfully tagged 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:1\n",
      "2021/09/15 16:21:59 Successfully executed container: acb_step_0\n",
      "2021/09/15 16:21:59 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/09/15 16:21:59 Pushing image: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:1, attempt 1\n",
      "The push refers to repository [3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72]\n",
      "5a7f5e85decc: Preparing\n",
      "02ef0708e96d: Preparing\n",
      "62f2be984077: Preparing\n",
      "0643484e55ce: Preparing\n",
      "e3da5cbf05f4: Preparing\n",
      "4020e998a8fd: Preparing\n",
      "a515078d8a86: Preparing\n",
      "676798be0ee9: Preparing\n",
      "d8b12f8634a8: Preparing\n",
      "a44c2175ce16: Preparing\n",
      "8ed2835b4e11: Preparing\n",
      "3236194bab08: Preparing\n",
      "4cce4df42af8: Preparing\n",
      "1b260ce6c815: Preparing\n",
      "346bf99f5c59: Preparing\n",
      "cc59b450fe4b: Preparing\n",
      "9f7d6b46eb7d: Preparing\n",
      "8f8f0266f834: Preparing\n",
      "4020e998a8fd: Waiting\n",
      "a515078d8a86: Waiting\n",
      "676798be0ee9: Waiting\n",
      "d8b12f8634a8: Waiting\n",
      "a44c2175ce16: Waiting\n",
      "8ed2835b4e11: Waiting\n",
      "3236194bab08: Waiting\n",
      "4cce4df42af8: Waiting\n",
      "1b260ce6c815: Waiting\n",
      "346bf99f5c59: Waiting\n",
      "cc59b450fe4b: Waiting\n",
      "9f7d6b46eb7d: Waiting\n",
      "8f8f0266f834: Waiting\n",
      "62f2be984077: Pushed\n",
      "5a7f5e85decc: Pushed\n",
      "0643484e55ce: Pushed\n",
      "02ef0708e96d: Pushed\n",
      "676798be0ee9: Pushed\n",
      "a515078d8a86: Pushed\n",
      "4020e998a8fd: Pushed\n",
      "d8b12f8634a8: Pushed\n",
      "8ed2835b4e11: Pushed\n",
      "a44c2175ce16: Pushed\n",
      "3236194bab08: Pushed\n",
      "4cce4df42af8: Pushed\n",
      "346bf99f5c59: Pushed\n",
      "cc59b450fe4b: Pushed\n",
      "8f8f0266f834: Pushed\n",
      "1b260ce6c815: Pushed\n",
      "9f7d6b46eb7d: Pushed\n",
      "e3da5cbf05f4: Pushed\n",
      "1: digest: sha256:fb5aa34b4c786f593e5e8c48d59342795934c5250288412b851d9f75cb568d58 size: 4099\n",
      "2021/09/15 16:23:43 Successfully pushed image: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:1\n",
      "2021/09/15 16:23:43 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/09/15 16:23:43 Pushing image: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:latest, attempt 1\n",
      "The push refers to repository [3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72]\n",
      "5a7f5e85decc: Preparing\n",
      "02ef0708e96d: Preparing\n",
      "62f2be984077: Preparing\n",
      "0643484e55ce: Preparing\n",
      "e3da5cbf05f4: Preparing\n",
      "4020e998a8fd: Preparing\n",
      "a515078d8a86: Preparing\n",
      "676798be0ee9: Preparing\n",
      "d8b12f8634a8: Preparing\n",
      "a44c2175ce16: Preparing\n",
      "8ed2835b4e11: Preparing\n",
      "3236194bab08: Preparing\n",
      "4cce4df42af8: Preparing\n",
      "1b260ce6c815: Preparing\n",
      "346bf99f5c59: Preparing\n",
      "cc59b450fe4b: Preparing\n",
      "9f7d6b46eb7d: Preparing\n",
      "8f8f0266f834: Preparing\n",
      "4020e998a8fd: Waiting\n",
      "4cce4df42af8: Waiting\n",
      "a515078d8a86: Waiting\n",
      "676798be0ee9: Waiting\n",
      "1b260ce6c815: Waiting\n",
      "d8b12f8634a8: Waiting\n",
      "346bf99f5c59: Waiting\n",
      "a44c2175ce16: Waiting\n",
      "8ed2835b4e11: Waiting\n",
      "cc59b450fe4b: Waiting\n",
      "3236194bab08: Waiting\n",
      "9f7d6b46eb7d: Waiting\n",
      "8f8f0266f834: Waiting\n",
      "e3da5cbf05f4: Layer already exists\n",
      "0643484e55ce: Layer already exists\n",
      "62f2be984077: Layer already exists\n",
      "02ef0708e96d: Layer already exists\n",
      "a515078d8a86: Layer already exists\n",
      "676798be0ee9: Layer already exists\n",
      "5a7f5e85decc: Layer already exists\n",
      "d8b12f8634a8: Layer already exists\n",
      "a44c2175ce16: Layer already exists\n",
      "4cce4df42af8: Layer already exists\n",
      "1b260ce6c815: Layer already exists\n",
      "8ed2835b4e11: Layer already exists\n",
      "3236194bab08: Layer already exists\n",
      "346bf99f5c59: Layer already exists\n",
      "9f7d6b46eb7d: Layer already exists\n",
      "cc59b450fe4b: Layer already exists\n",
      "8f8f0266f834: Layer already exists\n",
      "4020e998a8fd: Layer already exists\n",
      "latest: digest: sha256:fb5aa34b4c786f593e5e8c48d59342795934c5250288412b851d9f75cb568d58 size: 4099\n",
      "2021/09/15 16:23:46 Successfully pushed image: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io/azureml/azureml_0bef94ec66a3edd2493292aee0d9de72:latest\n",
      "2021/09/15 16:23:46 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 120.204041)\n",
      "2021/09/15 16:23:46 Populating digests for step ID: acb_step_0...\n",
      "2021/09/15 16:23:47 Successfully populated digests for step ID: acb_step_0\n",
      "2021/09/15 16:23:47 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 104.345924)\n",
      "2021/09/15 16:23:47 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.276081)\n",
      "2021/09/15 16:23:47 The following dependencies were found:\n",
      "2021/09/15 16:23:47 \n",
      "- image:\n",
      "    registry: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io\n",
      "    repository: azureml/azureml_0bef94ec66a3edd2493292aee0d9de72\n",
      "    tag: latest\n",
      "    digest: sha256:fb5aa34b4c786f593e5e8c48d59342795934c5250288412b851d9f75cb568d58\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210714.v1\n",
      "    digest: sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 3f2dd7bfde284e568ce4f4edc3bb52e8.azurecr.io\n",
      "    repository: azureml/azureml_0bef94ec66a3edd2493292aee0d9de72\n",
      "    tag: \"1\"\n",
      "    digest: sha256:fb5aa34b4c786f593e5e8c48d59342795934c5250288412b851d9f75cb568d58\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210714.v1\n",
      "    digest: sha256:4ecdbdb2fbc42ffe26c34a74464310318c8f212ef57e5fbd5373509e5fec533c\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cx4 was successful after 3m53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt\n",
      "========================================================================================================================\n",
      "2021-09-15T16:27:29Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=92217 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-09-15T16:27:29Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/mounts/workspaceblobstore\n",
      "2021-09-15T16:27:30Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-09-15T16:27:30Z Starting output-watcher...\n",
      "2021-09-15T16:27:30Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1e5b59c0734bdc528077f509e1d397fe\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "886c27cf0865: Pulling fs layer\n",
      "7c9062f12448: Pulling fs layer\n",
      "7268e886f68a: Pulling fs layer\n",
      "e1fdaab561c7: Pulling fs layer\n",
      "ccb2816215bd: Pulling fs layer\n",
      "55d70b17f345: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "886c27cf0865: Waiting\n",
      "7c9062f12448: Waiting\n",
      "7268e886f68a: Waiting\n",
      "e1fdaab561c7: Waiting\n",
      "ccb2816215bd: Waiting\n",
      "55d70b17f345: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "64788f86be3f: Verifying Checksum\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "886c27cf0865: Verifying Checksum\n",
      "886c27cf0865: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "e1fdaab561c7: Verifying Checksum\n",
      "e1fdaab561c7: Download complete\n",
      "7268e886f68a: Verifying Checksum\n",
      "7268e886f68a: Download complete\n",
      "ccb2816215bd: Verifying Checksum\n",
      "ccb2816215bd: Download complete\n",
      "55d70b17f345: Verifying Checksum\n",
      "55d70b17f345: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "7c9062f12448: Verifying Checksum\n",
      "7c9062f12448: Download complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "886c27cf0865: Pull complete\n",
      "7c9062f12448: Pull complete\n",
      "7268e886f68a: Pull complete\n",
      "e1fdaab561c7: Pull complete\n",
      "ccb2816215bd: Pull complete\n",
      "55d70b17f345: Pull complete\n",
      "Digest: sha256:d0c5e40cf440c619e721faa614dc94fe56cb6c41768532d169421cbe2288edc7\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "2021-09-15T16:27:56Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-09-15T16:27:56Z Check if container 460a4fe5-0778-44fe-b089-d4bc6138fef3_DataSidecar already exist exited with 0, \n",
      "\n",
      "b4ec44bb0a9f83a9f50c332dc346a12425ec2a8aca2d8f160481b10df61ee433\n",
      "2021-09-15T16:28:04Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-09-15T16:28:04Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-5496baf945a8bb4915ba93c3ab2868c1-42896455d3ae0d79-01 -sshRequired=false] \n",
      "2021/09/15 16:28:04 Starting App Insight Logger for task:  containerSetup\n",
      "2021/09/15 16:28:04 Version: 3.0.01706.0003 Branch: 2021-09-03 Commit: cd0f702\n",
      "2021/09/15 16:28:04 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/09/15 16:28:04 Starting infiniband setup\n",
      "2021/09/15 16:28:04 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/09/15 16:28:04 Returning Python Version as 3.7\n",
      "2021/09/15 16:28:04 VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/09/15 16:28:04 VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021-09-15T16:28:04Z VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/09/15 16:28:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/09/15 16:28:04 Not setting up Infiniband in Container\n",
      "2021/09/15 16:28:04 Not setting up Infiniband in Container\n",
      "2021-09-15T16:28:04Z Not setting up Infiniband in Container\n",
      "2021/09/15 16:28:04 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/09/15 16:28:04 Returning Python Version as 3.7\n",
      "2021/09/15 16:28:04 sshd inside container not required for job, skipping setup.\n",
      "2021/09/15 16:28:05 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2021/09/15 16:28:05 App Insight Client has already been closed\n",
      "2021/09/15 16:28:05 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-09-15T16:28:05Z Starting docker container succeeded.\n",
      "2021-09-15T16:28:05Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt\n",
      "===============================================================================================================\n",
      "[2021-09-15T16:28:02.647266] Entering job preparation.\n",
      "[2021-09-15T16:28:03.395232] Starting job preparation.\n",
      "[2021-09-15T16:28:03.395262] Extracting the control code.\n",
      "[2021-09-15T16:28:03.395954] Starting extract_project.\n",
      "[2021-09-15T16:28:03.395998] Starting to extract zip file.\n",
      "[2021-09-15T16:28:03.418788] Finished extracting zip file.\n",
      "[2021-09-15T16:28:03.422333] Using urllib.request Python 3.0 or later\n",
      "[2021-09-15T16:28:03.422474] Start fetching snapshots.\n",
      "[2021-09-15T16:28:03.422556] Start fetching snapshot.\n",
      "[2021-09-15T16:28:03.422574] Retrieving project from snapshot: 781eb6de-684f-44c1-99f0-4e8211f3ac70\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 51\n",
      "[2021-09-15T16:28:03.687289] Finished fetching snapshot.\n",
      "[2021-09-15T16:28:03.687334] Start fetching snapshot.\n",
      "[2021-09-15T16:28:03.687436] Retrieving project from snapshot: 05664243-e8a8-4772-8117-70719b5ba106\n",
      "[2021-09-15T16:28:11.486900] Finished fetching snapshot.\n",
      "[2021-09-15T16:28:11.486938] Finished fetching snapshots.\n",
      "[2021-09-15T16:28:11.487067] Finished extract_project.\n",
      "[2021-09-15T16:28:11.487283] Finished fetching and extracting the control code.\n",
      "[2021-09-15T16:28:11.495433] Start run_history_prep.\n",
      "[2021-09-15T16:28:11.502547] Job preparation is complete.\n",
      "[2021-09-15T16:28:11.502983] Entering Data Context Managers in Sidecar\n",
      "[2021-09-15T16:28:11.503917] Running Sidecar prep cmd...\n",
      "[2021-09-15T16:28:11.889657] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3\n",
      "[2021-09-15T16:28:11.890767] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.32.0 azureml-dataprep==2.20.1. Session id: 65dd7ffb-41d9-427f-9391-2b1b335832bb. Run id: 460a4fe5-0778-44fe-b089-d4bc6138fef3.\n",
      "Processing 'diabetes_batch'.\n",
      "Mode: 'mount'.\n",
      "Path on compute is specified: 'False'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"6f5d30d4-fc73-4641-ad9c-8c28518278a5\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='dp-100-module1-ml', subscription_id='2bfd1cd3-851a-4267-8cd5-eff6767da991', resource_group='dp100-esi-course')\"\n",
      "  }\n",
      "}\n",
      "Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5.\n",
      "Mounted diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5 as folder.\n",
      "Processing 'inferences'.\n",
      "Mode: 'mount'.\n",
      "Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore'.\n",
      "Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5\n",
      "Set OutputDataset inferences's target path to /tmp/43818f63-7989-45e0-a8e7-95994bb08d4c\n",
      "[2021-09-15T16:28:25.654426] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-09-15T16:28:26.079377] Ran Sidecar prep cmd.\n",
      "[2021-09-15T16:28:26.079528] Running Context Managers in Sidecar complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/09/15 16:29:12 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/09/15 16:29:12 Version: 3.0.01706.0003 Branch: 2021-09-03 Commit: cd0f702\n",
      "2021/09/15 16:29:12 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/09/15 16:29:12 Send process info logs to master server succeeded\n",
      "2021/09/15 16:29:12 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/09/15 16:29:12 Send process info logs to master server succeeded\n",
      "[2021-09-15T16:29:12.072438] Entering context manager injector.\n",
      "[2021-09-15T16:29:12.562243] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.33.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'])\n",
      "Script type = None\n",
      "[2021-09-15T16:29:12.566159] Entering Run History Context Manager.\n",
      "[2021-09-15T16:29:13.219033] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3\n",
      "[2021-09-15T16:29:13.219423] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.33.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'diabetes_batch']\n",
      "[2021-09-15T16:29:13.219462] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.33.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/tmp/43818f63-7989-45e0-a8e7-95994bb08d4c', '--input_fds_0', 'diabetes_batch']\n",
      "\n",
      "2021/09/15 16:29:17 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "\n",
      "[2021-09-15T16:30:10.712256] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.2014310359954834 seconds\n",
      "[2021-09-15T16:30:11.068356] Finished context manager injector.\n",
      "2021/09/15 16:30:12 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/09/15 16:30:12 Send process info logs to master server succeeded\n",
      "2021/09/15 16:30:12 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2021/09/15 16:30:12 Process Exiting with Code:  0\n",
      "2021/09/15 16:30:12 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt\n",
      "===============================================================================================================\n",
      "[2021-09-15T16:30:13.538826] Entering job release\n",
      "[2021-09-15T16:30:14.329288] Starting job release\n",
      "[2021-09-15T16:30:14.329889] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 357\n",
      "[2021-09-15T16:30:14.330738] job release stage : upload_datastore starting...[2021-09-15T16:30:14.330968] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-09-15T16:30:14.331011] job release stage : execute_job_release starting...\n",
      "\n",
      "[2021-09-15T16:30:14.332027] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-09-15T16:30:14.345779] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-09-15T16:30:14.348451] Entering context manager injector.\n",
      "[2021-09-15T16:30:14.352571] job release stage : upload_datastore completed...\n",
      "[2021-09-15T16:30:14.465292] job release stage : send_run_telemetry starting...\n",
      "[2021-09-15T16:30:14.484604] get vm size and vm region successfully.\n",
      "[2021-09-15T16:30:14.494529] get compute meta data successfully.\n",
      "[2021-09-15T16:30:14.547959] job release stage : execute_job_release completed...\n",
      "[2021-09-15T16:30:14.667871] post artifact meta request successfully.\n",
      "[2021-09-15T16:30:14.701550] upload compute record artifact successfully.\n",
      "[2021-09-15T16:30:14.701768] job release stage : send_run_telemetry completed...\n",
      "[2021-09-15T16:30:14.702232] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-09-15T16:30:14.702414] Running Sidecar release cmd...\n",
      "[2021-09-15T16:30:14.715883] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5: Invalid argument\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5.\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-09-15T16:30:14.763406] Removing absolute paths from host...\n",
      "[2021-09-15T16:30:14.764056] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-09-15T16:30:15.544352] Ran Sidecar release cmd.\n",
      "[2021-09-15T16:30:15.544743] Job release is complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt\n",
      "===============================================================================================================\n",
      "[2021-09-15T16:30:14.140872] Entering job release\n",
      "[2021-09-15T16:30:14.924355] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-09-15T16:30:14.924587] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-09-15T16:30:14.924785] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-09-15T16:30:14.925469] Running Sidecar release cmd...\n",
      "[2021-09-15T16:30:14.934775] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/diabetes_batch_6f5d30d4-fc73-4641-ad9c-8c28518278a5.\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/dp-100-module1-ml/azureml/460a4fe5-0778-44fe-b089-d4bc6138fef3/wd/inferences_workspaceblobstore.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-09-15T16:30:14.987089] Removing absolute paths from host...\n",
      "[2021-09-15T16:30:14.987376] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-09-15T16:30:15.719232] Ran Sidecar release cmd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': '95976bd4-cfa1-462d-a90a-e0b580ccb54f', 'target': 'dp100clusterday2', 'status': 'Completed', 'startTimeUtc': '2021-09-15T16:19:51.634607Z', 'endTimeUtc': '2021-09-15T16:31:11.005002Z', 'properties': {'azureml.reusedrunid': '460a4fe5-0778-44fe-b089-d4bc6138fef3', 'azureml.reusednodeid': '4301f812', 'azureml.reusedpipeline': 'cf7c1d65-c882-427c-ab20-e9c754093d42', 'azureml.reusedpipelinerunid': 'cf7c1d65-c882-427c-ab20-e9c754093d42', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '1709d5ed', 'ContentSnapshotId': '781eb6de-684f-44c1-99f0-4e8211f3ac70', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '20d7c65b-f8c3-4358-a10a-4ca367d7e076', 'azureml.pipelinerunid': 'f710fcc9-20f6-4da5-98c4-4292f3d93ce2', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.33.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'dp100clusterday2', 'dataReferences': {}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': '6f5d30d4-fc73-4641-ad9c-8c28518278a5', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': '/tmp/43818f63-7989-45e0-a8e7-95994bb08d4c/', 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-09-15T16:19:51Z_46a0c023', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'pip', {'pip': ['azureml-defaults']}], 'name': 'azureml_e220b045f6c3c3008b1a386af067185d'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'jarLibraries': [], 'eggLibraries': [], 'whlLibraries': [], 'pypiLibraries': [], 'rCranLibraries': [], 'mavenLibraries': []}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=2KnGoaruaYTEeJaR59M8AaFb3w6ZkZrluxXu6Jnz9R0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/55_azureml-execution-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt?sv=2019-07-07&sr=b&sig=Vg5p9QrLoydGyjvacYhqNZOsqyB9T08NIN%2FmAlU44Oc%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/55_azureml-execution-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt?sv=2019-07-07&sr=b&sig=JR7NmaDl99y%2FSdr0KWgybbeh69TRuuctBaU7gaSkCs0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/65_job_prep-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/65_job_prep-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt?sv=2019-07-07&sr=b&sig=EIYqHrb4R%2F1Wg3lzWXqRVeh98%2BpO18RfmUltLlGzMwA%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/65_job_prep-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt?sv=2019-07-07&sr=b&sig=WpzZ1rvXHLgOU3n8kfaZodVxL3FQQgZYNWR8cfP40%2FY%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=lu0z8C4WsvuM4zbUBj3fNuLVz5eTIUpb7mTJAhCXGB0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/75_job_post-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/75_job_post-tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d.txt?sv=2019-07-07&sr=b&sig=jJ7GHWqvvzFHvpvwoel1CZwUmYm6ygbompOHt34rxiY%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/75_job_post-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/75_job_post-tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d.txt?sv=2019-07-07&sr=b&sig=iP9BfcW3SoD4vSFrk%2F7WEPNewukt30ei4aBtZTPCQJ8%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/process_info.json': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=7dl0sVX2SPkzlC2xDGDvjKm5pWikPsGPQnQbKoJomUs%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'azureml-logs/process_status.json': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=%2BPExSbDCnnWFpKEYeWYoHQ%2FTiOgPX3%2FFIBQccRo6yiA%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/101_azureml.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/101_azureml.log?sv=2019-07-07&sr=b&sig=q%2BuqjElW%2B1DNBNO9YIgwoTPoQaql10RqOY6pYStbYK4%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/87_azureml.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/87_azureml.log?sv=2019-07-07&sr=b&sig=cHQSC0SPFm%2BxOUbo4weqIMnmUNOTYzHaxYgASovdXDY%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=%2BmQ6QHctGTf6qmdwgVpDo0Mn3oIWSOTjUwk4Zm49tpg%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=HLvxx8ZTxwjwe67IvPWl%2BVDwwETIj2yDSwaqyadDUmg%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=hXsUtXzFaxuNDj6UXHwH5QIKanSNWJsJjQYGfb9tRGc%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=36pdaa3hr26wYT8pPSQ%2F3hDScFYQl%2FSgB3cvUTzbmvQ%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=MTp6OpZHAVx6i0hiFR3sy%2BvorJ69TGq%2FGy6t7GeM4O0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/all.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/all.log?sv=2019-07-07&sr=b&sig=pgkQbUOY%2Fgg5EnUIiAcUbxmUfg4FR23tRzVa8%2BMz2L0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/task.enter_contexts.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=XSMixi%2Bu071vjZyPKZV%2BEE41ymUbioDRzKLBx4RMlc0%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/task.exit_contexts.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_11558cd55b6330f2eafd3140d32fd8c22905f26a00ab33ff4065bc8d274938fb_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=cRDEoBvwCHcMJAaPn2AUQoTnrH8R%2FVHwRZjtZboCipM%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/all.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/all.log?sv=2019-07-07&sr=b&sig=nsJp1tviq%2B%2Fs6mB5k3494l7laaxMT4xZFYU80C9S8zg%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/task.enter_contexts.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=Nn2XJMnK1uuMtB%2BdmwfMlPL6gjNnvirae87vNVe0pm4%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/task.exit_contexts.log': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/sidecar/tvmps_b85122815f663fc562381fd9e3bf94217375b0873eb0b4887ccd1a75061b3a1a_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=yMkRMb6fVNKsSHod3VBllWVpma4Uu73j44a6trPJCvo%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=bIxnGiaNSqI9Xtt5%2F0ZW9nSy8LDp96xSJ%2BcLBlnFSI4%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.460a4fe5-0778-44fe-b089-d4bc6138fef3/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=T4U9qaVoRd6a4uD9zSMcqq6nPIFZua8KPNaM09N6kbw%3D&st=2021-09-15T16%3A20%3A19Z&se=2021-09-16T00%3A30%3A19Z&sp=r'}, 'submittedBy': 'Rubaiyat Ashna'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'f710fcc9-20f6-4da5-98c4-4292f3d93ce2', 'status': 'Completed', 'startTimeUtc': '2021-09-15T16:25:12.803104Z', 'endTimeUtc': '2021-09-15T16:31:14.943311Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.f710fcc9-20f6-4da5-98c4-4292f3d93ce2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=OP7jTdc0%2BNXEGKdOgoyWMeorMP6oyER9i%2BakwnGQt6w%3D&st=2021-09-15T16%3A21%3A16Z&se=2021-09-16T00%3A31%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.f710fcc9-20f6-4da5-98c4-4292f3d93ce2/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=PKKFtS%2B3syvfAuskowIjEm2aRAydC1klCaAzo9cUuLc%3D&st=2021-09-15T16%3A21%3A16Z&se=2021-09-16T00%3A31%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.f710fcc9-20f6-4da5-98c4-4292f3d93ce2/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=MLI6aB9RE9Vft1IBFHho8YdK9QkcQ0ir6IARXkJvxsU%3D&st=2021-09-15T16%3A21%3A16Z&se=2021-09-16T00%3A31%3A16Z&sp=r'}, 'submittedBy': 'Rubaiyat Ashna'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       File  Prediction\n",
       "0     1.csv           0\n",
       "1    10.csv           0\n",
       "2   100.csv           1\n",
       "3    11.csv           1\n",
       "4    12.csv           1\n",
       "5    13.csv           1\n",
       "6    14.csv           0\n",
       "7    15.csv           0\n",
       "8    16.csv           1\n",
       "9    17.csv           1\n",
       "10   18.csv           0\n",
       "11   19.csv           0\n",
       "12    2.csv           1\n",
       "13   20.csv           0\n",
       "14   21.csv           0\n",
       "15   22.csv           0\n",
       "16   23.csv           0\n",
       "17   24.csv           0\n",
       "18   25.csv           1\n",
       "19   26.csv           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline and use its REST Interface\n",
    "\n",
    "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/eec3ff7e-a398-4c9e-8f82-891c1e07ff86?wsid=/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourcegroups/dp100-esi-course/workspaces/dp-100-module1-ml\" target=\"_blank\" rel=\"noopener\">eec3ff7e-a398-4c9e-8f82-891c1e07ff86</a></td><td>Active</td><td><a href=\"https://canadacentral.api.azureml.ms/pipelines/v1.0/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourceGroups/dp100-esi-course/providers/Microsoft.MachineLearningServices/workspaces/dp-100-module1-ml/PipelineRuns/PipelineSubmit/eec3ff7e-a398-4c9e-8f82-891c1e07ff86\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: diabetes-batch-pipeline,\n",
       "Id: eec3ff7e-a398-4c9e-8f82-891c1e07ff86,\n",
       "Status: Active,\n",
       "Endpoint: https://canadacentral.api.azureml.ms/pipelines/v1.0/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourceGroups/dp100-esi-course/providers/Microsoft.MachineLearningServices/workspaces/dp-100-module1-ml/PipelineRuns/PipelineSubmit/eec3ff7e-a398-4c9e-8f82-891c1e07ff86)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://canadacentral.api.azureml.ms/pipelines/v1.0/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourceGroups/dp100-esi-course/providers/Microsoft.MachineLearningServices/workspaces/dp-100-module1-ml/PipelineRuns/PipelineSubmit/eec3ff7e-a398-4c9e-8f82-891c1e07ff86\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
    "\n",
    "> **Note**: A real application would require a service principal with which to be authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the run ID, we can use the **RunDetails** widget to view the experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b?wsid=/subscriptions/2bfd1cd3-851a-4267-8cd5-eff6767da991/resourcegroups/dp100-esi-course/workspaces/dp-100-module1-ml&tid=a9c3340e-e390-4e58-8d69-193d480ee19a\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b', 'status': 'Completed', 'startTimeUtc': '2021-09-15T16:32:36.170571Z', 'endTimeUtc': '2021-09-15T16:32:37.632118Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': 'eec3ff7e-a398-4c9e-8f82-891c1e07ff86'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=QiCb6HCG8o%2FmCeyvvzYJW%2FaNsOoGSu%2FLCxGpQcu31XU%3D&st=2021-09-15T16%3A22%3A44Z&se=2021-09-16T00%3A32%3A44Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=k6I1LPq47AoQrPnlZXTeyEIWcQtpgNl80VddXpHNUwQ%3D&st=2021-09-15T16%3A22%3A44Z&se=2021-09-16T00%3A32%3A44Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://dp100module1ml0619782805.blob.core.windows.net/azureml/ExperimentRun/dcid.8e760a4b-da4a-41cf-9252-c8cf8e0f5d3b/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=JjPey5FdRzyGKlJb3HO5Ii7S7%2Bw8cjSnfI2HUnU9YOc%3D&st=2021-09-15T16%3A22%3A44Z&se=2021-09-16T00%3A32%3A44Z&sp=r'}, 'submittedBy': 'Rubaiyat Ashna'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\n",
    "\n",
    "# Block until the run completes\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the pipeline run to complete, and then run the following cell to see the results.\n",
    "\n",
    "As before, the results are in the output of the first pipeline step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       File  Prediction\n",
       "0     1.csv           0\n",
       "1    10.csv           0\n",
       "2   100.csv           1\n",
       "3    11.csv           1\n",
       "4    12.csv           1\n",
       "5    13.csv           1\n",
       "6    14.csv           0\n",
       "7    15.csv           0\n",
       "8    16.csv           1\n",
       "9    17.csv           1\n",
       "10   18.csv           0\n",
       "11   19.csv           0\n",
       "12    2.csv           1\n",
       "13   20.csv           0\n",
       "14   21.csv           0\n",
       "15   22.csv           0\n",
       "16   23.csv           0\n",
       "17   24.csv           0\n",
       "18   25.csv           1\n",
       "19   26.csv           0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Remove the local results folder if left over from a previous run\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# Get the run for the first step and download its output\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# Traverse the folder hierarchy and find the results file\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# cleanup output format\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# Display the first 20 results\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a pipeline that can be used to batch process daily patient data.\n",
    "\n",
    "**More Information**: For more details about using pipelines for batch inferencing, see the [How to Run Batch Predictions](https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions) in the Azure Machine Learning documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
